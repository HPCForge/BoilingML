

class (nn.Modules):
    

    def init(in_size,

            in_channels,
            out_channels,
            hidden_channels,
            ch_mults,
            is_attn,
            activation='gelu',
            mid_attn=False,
            norm=True,
            use1x1=True,
            #trunk param
            
            ):


            self.__init_modules()
            self.params = self.__init_params



    def __init_modules(self):
        modules = nn.MoudleDict()
        modules["Branch"] = Model(*args)
         modules['TrLinM1'] = nn.Linear(self.trunk_dim, self.width)
        modules['TrActM1'] = self.Act
        for i in range(2, self.trunk_depth):
            modules['TrLinM{}'.format(i)] = nn.Linear(self.width, self.width)
            modules['TrActM{}'.format(i)] = self.Act
        return modules
    
    def __branch_checkpoint(checkpoint_file):
        modules["Branch"].load_state_dict(torch.load(checkpoint_file))
    

    def __init_params(self):
        params = nn.ParameterDict()
        params['bias'] = nn.Parameter(torch.zeros([1]))
        return params

    
    def __initialize(self):
        for i in range(1, self.trunk_depth):
            self.weight_init_(self.modus['TrLinM{}'.format(i)].weight)
            nn.init.constant_(self.modus['TrLinM{}'.format(i)].bias, 0)

    def forward(self, x, positional_query_vector):
        x_branch = x
        x_branch = self.modules["Branch"](x_branch)

        for i in range(1, trunk_depth):
            positional_query_vector = self.modules[f'TrActM{i}'](positional_query_vector)
        
        return torch.sum(x_branch * positional_query_vector, dim=-1, keepdim=True) + self.params['bias']

    






